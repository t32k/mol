<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Performance on MOL</title>
    <link>https://t32k.me/mol/categories/performance/</link>
    <description>Recent content in Performance on MOL</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 09 Jan 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://t32k.me/mol/categories/performance/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>手軽にCIを体験してみたい・その2</title>
      <link>https://t32k.me/mol/log/casual-continuous-integration-2/</link>
      <pubDate>Thu, 09 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/casual-continuous-integration-2/</guid>
      <description>前回の記事が全然手軽じゃない気がしてきたので、今回も幾分かマシにCIを体験するというかCIサーバ立てずにがんばってみる。
前回はTravisとYSlowを使ってパフォーマンステストをしたけど、今回はJenkinsとWebPagetestを使って全く同じことをしてみる。
やっぱしTravisの設定が慣れないんだなぁ。ちなみに普通のユニットテストとかだったら、アクセストークンとか必要ないのでもっと簡単にできる。僕はGruntプラグインの開発で使用している。
 grunt-csso/.travis.yml grunt-csso/package.json  例えば、grunt-cssoの設定は上記みたいな感じ。ymlは実行環境指定してあるだけだし、package.jsonはgrunt testのコマンドを実行してるだけで、要はnodeunitテストだ。ローカルでやるのとたいして変わらない。
なので、おもしろくない。
Jenkins やっぱり私、Jenkins触りたいんですですおおおお＾q＾！ってことで、世の中にはクラウドサービスとしてJenkinsを使えるそうで、CloudBeesってとこのDEV@cloud使ってみる。便利な世の中だ。
 CloudBees: The Java PaaS Company  Freeでは月300分までのビルドまでしかできなかったり制限あるけど、ちょっとJenkinsに触りたいんです欲求ぐらいなら満たせる。
Jenkinsシステム設定 まず、GitHubとJenkinsの連携だけどDEV@cloudのJenkinsはGit Pluginがデフォルトでインストールしてあるのでこちらでインストールしなくてもいいので楽です。
CloudBees DEV@cloud AuthorizationでCloudBees Public KeyをGitHubのAccount SettingsのSSH Keysに登録しておく。
次に後述するWebPagetest(WPT)をNode.jsから利用するのでJenkinsにNode.jsをインストールしたい。NodeJS Pluginを検索してインストールすれば、Jenkinsのシステム設定からNode.jsをバージョン管理できるようになる。
 NodeJS Plugin - Jenkins - Jenkins Wiki  またwebpagetestパッケージが必要なので、Global npm packages to installからインストールできるようにしておく。
Jenkinsビルド設定 新規ジョブ作成から『フリースタイル・プロジェクトのビルド』を選択する。
ソースコード管理システムはGitを選択しレポジトリURLを設定する。ここではgit@github.com:t32k/maple.gitを指定。
次はビルド・トリガで、『SCMをポーリング』にチェックを入れ、スケジュールには本来Cronの設定を書くが今回はGitHubのServer Hookをトリガとするので、何も入力しない（便宜上、チェックをいれるらしい）。
GitHubのMapleのSettingsからService Hooksで、Jenkins (Git plugin)を選択肢、Jenkins Urlを入力し、Activeにする。これでGitフックの設定は終わり。MapeレポジトリにコミットするとJenkinsがビルドする。
ほかにもいろいろ方法があるらしいので下記ページを参照してほしい。
 GithubからJenkinsへのServer Hook - Qiita [キータ]  次はビルド環境で、Provide Node &amp;amp; npm bin/ folder to PATHにチェックをする。</description>
    </item>
    
    <item>
      <title>手軽にCIを体験してみたい</title>
      <link>https://t32k.me/mol/log/casual-continuous-integration/</link>
      <pubDate>Tue, 07 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/casual-continuous-integration/</guid>
      <description>昨年のFrontrend/06では、全くもってながら個人的な趣向のもと継続インテグレーション（CI:Continuous Integration）をテーマに開催した。もはや、フロントエンドとは！という感じだが、非常に良いイベントだったと思う。
基本的に昨今のフロントエンドは膨大なタスクに追われている、そのようなタスクを手動でちまちまやっていては手戻りやミスなど必ず発生するので自動化すべきである。フロントエンドの自動化はGruntなどがあるが、結局フロントだけで問題を解決しようとすると問題（限界）があったりするので、CIサーバーとか使ったほうがいいよね。てかフロントエンドの人も慣れておいたほうがいいよねって話。
しかし、フロントエンドの人がいちからJenkinsを立ち上げたりするのもさほど面倒でもないが多少の心理的障壁があるので、もっとカジュアルに利用したい。
Frontend/06の佐竹さんのセッションでCIを構成する要素として、Build・Test・Commitの3つがあると紹介されていた。Commitは普段Gitを使ってるから馴染み深いというかGitHub使ってるよね？みんな！！ってことで問題無いとして、Build/TestをなんとかCIサーバーでやってもらいたい。Testに関してはJavaScriptのTestなんかフロントエンドの人もやるので問題ないかと思うけど僕はそんなJavaScriptとか書かないのでよくわからないので、今回はWeb Performanceのテストをやってみるよ。
今回のGitHubのレポジトリ(master)にPushしたら、Travisがgh-pagesブランチに同じ内容をコミットして反映された(gh-pagesの)ページのパフォーマンスをYSlowで検証してみるという流れだ。
gh-pagesをDev環境と見立てて、Dev環境でBuildした内容がパフォーマンス的に不適切（テストが失敗）ならProduction環境にはリリースできない・させないというようなサイクルを想定している。
Travis-CI CIサーバーはなにもJenkinsだけではない。GitHub上でレポジトリを管理しているのなら連携しているTravis-CIを使用するのが何かと都合がよい。
Travisを使うにはアカウントを連携して、自分のプロフィールから検証したいレポジトリをONにする。
Travisをどのように使用するかは.travis.ymlというファイルに記述する。Mapleでの設定は下記ファイルを見てもらえればよい。
 maple/.travis.yml at master · t32k/maple  language: node_js node_js: 0.10  最初の行は実行環境を指定する。node.jsを使ったテストがしたいので、node_jsを指定する。バージョンは0.8、0.10とか複数指定できる。
env: global: &amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEAD - GIT_AUTHOR_NAME=YOUR_ID - GIT_AUTHOR_EMAIL=YOUR_MAIL_ADDRESS - GIT_COMMITTER_NAME=YOUR_ID - GIT_COMMITTER_EMAIL=YOUR_MAIL_ADDRESS ======= - GIT_AUTHOR_NAME=your-name - GIT_AUTHOR_EMAIL=your-mail - GIT_COMMITTER_NAME=your-name - GIT_COMMITTER_EMAIL=your-mail &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; bc00bb731570eceb7f151001eafb282b7ce2fe56 - secure: &amp;quot;Xtk................&amp;quot;  TravisからGitHubにコミットするには、OAuth access tokensが必要になのでここから発行する。そんでトークンをこんなパブリックなところに公開できないので、コマンドラインのtravisで暗号化したのがsecureのところ。
$ gem install travis $ travis encrypt -r t32k/maple &amp;quot;GH_TOKEN=&amp;lt;生成したトークン&amp;gt;&amp;quot;  こんな感じで暗号化する。詳しくは下記のサイトを参照して欲しい。
 Middleman で作った web サイトを Travis + GitHub pages でお手軽に運用する - tricknotesのぼうけんのしょ MiddlemanとTravis CIでgh-pagesを運用したら身長が伸びた | 1000ch.</description>
    </item>
    
    <item>
      <title>WebPagetest in 5 minutes</title>
      <link>https://t32k.me/mol/log/webpagetest-5-minutes/</link>
      <pubDate>Tue, 05 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/webpagetest-5-minutes/</guid>
      <description>WebPagetest in 5 minutes // Vimeo WebPagetest in 5 minutes // Speaker Deck  WebPagetest 2013年10月30日にサイバーエージェントで行われたFrontrend x Chrome Tech Talk Night ExtendedでWebPagetestでライトニングトークしてきたのでメモしておく。
公式サイトにはAddyやJake、Paulの動画も既に公開されている。しかも通訳付きなので参加できなかった方もぜひ見てほしい。
さて、今回紹介するWebPagetestだが、いまいち日本で人気のないようだから紹介してみる。
私の仕事はWebパフォーマンス改善のタスクを主な業務としている。弊社がリリースしているWebアプリで遅いことが確認されるとその原因を調査する。その時に使うツールがChromeの拡張機能のPageSpeed Insightsと、WebPagetestだ。PageSpeedはサクッと調べたい時に使い、WebPagetestを腰を据えてじっくり調べたい時に使う。今回紹介するのはWebPagetestのほうだ。
 WebPagetest - Website Performance and Optimization Test  WebPagetestを使うには上記のサイトから、調べたいページのURLを入力して『START TEST』のボタンを押すだけだ。しばらくするとテスト結果画面が表示されるのでここからボトルネックを見つける。さまざまなオプションがあるが基本的な使い方はこの通りである。
WebPagetestはPageSpeed(DevTools)に似たような機能も提供しているが、多くの機能がある。First ByteやStart Render、DOM Elementsなどといった指標を取得することも可能であれば、Waterfall View、Connection View、FilmstripやScripted Testといったことも可能である。ここでは全部紹介しきれないのでWebPagetestの最も素晴らしい機能と言っても過言ではないSpeed Indexについて紹介する。
Speed Index Speed Indexは、端的に言えば体感速度を指標化したようなものだ。
 Speed Index - WebPagetest Documentation  詳しくは上記のドキュメントを読んでもらいたい。簡単に説明するとページのVisual Progressというのがあって、文字通りページがどれだけ描画されているかの進捗度である。スライドのA：青とB：赤のVisual Progressだと、どっちが良いかは自明だろう。どちらも12秒ほどの読み込み時間がかかっているが、青のほうは、1秒の段階で90%ほど描画が完了しているのに対して、赤のほうは11秒くらいまで20%未満のVisual Progressだ。当然、青のほうが体感速度的には早いと感じるであろう。
Speed Indexというのはこの単位時間辺りのVisual Completeしていない度合いの総和である。つまり、Speed Indexは小さい方はがよりよいということである。
上記の数式の意味は、0秒から読み込みが完了するまでのミリセカンド毎に、1からVisual Completeをひいたものを足した総和ということを意味している。
これにより、同じ読み込み時間であってもSpeed Indexを見ればどちらが良いのか判断できるようになる。</description>
    </item>
    
    <item>
      <title>HTTPリクエストを減らすために【終章】我々には1000msの猶予しか残されていない</title>
      <link>https://t32k.me/mol/log/reduce-http-requests-one-second/</link>
      <pubDate>Fri, 23 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/reduce-http-requests-one-second/</guid>
      <description>このシリーズはHTTPリクエストの理解を通じてWebパフォーマンスの重要性について考える5章構成になっている。
 【序章】HTTPリクエストは甘え 【CSS Sprite編】スプライト地獄からの解放 【WebFont編】ドラッグ＆ドロップしてコマンド叩いてウェーイ 【DataURI編】遅延ロードでレンダリングブロックを回避 【終章】我々には1000msの猶予しか残されていない  最終日は、我々フロントエンドデベロッパーに課せられた理想と現実のはざまについて冷静と情熱のあいだらへんで考えていく。まずは下記のブログを読んでもらいたい。
 Google ウェブマスター向け公式ブログ: スマートフォンサイトの読み込み速度を改善するために  まぁ読まなくてもいいのだが、ここで述べられている重要なことは2つ。
 モバイルの平均読み込み時間は7秒 しかし、ユーザーは1秒未満を求めている  平均読み込み時間の7秒というのは、Googleアナリティクスのサイトの速度という機能があって、そこから集計し出されたデータによるものだ。
 入力に対して0.1秒以上1秒未満でコンピューターからの応答があるとき、我々はその間にコンピューターが結果を表示しようとしているように感じる。ユーザーは多少遅いとは思っても、1秒間は進行中の一連の自分の考えに集中したままでいる。
  10の累乗： ユーザーエクスペリエンスにおける時間スケール － U-Site  1秒未満というのはヤコブ・ニールセン博士というユーザビリティの偉い人がいるのだが、彼のブログで述べられていたことだ。要は1秒以内にコンピューターから応答があった場合は、自分がそれをダイレクトに操作している感覚をあたえ、ユーザーエクスペリエンス的によろしいということ。それ以上の時間をかかってしまうとユーザーはストレスを抱え、タスクを放棄しかねないと言っている。
ということで、今回は1000msに挑戦してみよう！という内容。
※ 括弧内の文字はDevToolsでの名称を記述
 WebPagetest Test Result - Tokyo : t32k.me/ - 08/20/13 05:04:45  上記は私のサイトをWebPagetestにかけた結果（TOKYOリージョン、Chrome 3G回線をエミュレート）。分かりやすくするために読み込むリソースをHTMLだけにしている（Image/CSS/JavaScript読み込んでいない）。しかし、それでも1.7秒近く読み込みに時間がかかっている。
 PageSpeed Insights でのモバイル解析 — Google Developers  さすがに1秒以内に読み込み完了するのは不可能に近いので、レンダリングを1秒以内にしようというのがGoogleさんの教え。
ここに書かれていることに、3G回線だとラウンドトリップタイムが約200~300msかかると言われており、仮に200msとした場合、DNS Lookupに1回ラウンドトリップ、TCPコネクション接続に1回ラウンドトリップ、HTTPリクエストとレスポンスで1回ラウンドトリップと合計3回のラウンドトリップで必ず600msは消費する。
Serverレスポンスタイムは完全のバックエンドのエンジニアさんの領域なので、 New Relicとか使ってボトルネック見つけてね！としか僕からは言えない。
結局、我々フロントエンドに残された時間は200msしかない(´・ω・`)

最近リニューアルしたPageSpeed Insightではモバイル版も評価してくれる。当然モバイル環境はシビアなのでデスクトップ評価と比べて点数は下がってしまう。そこではモバイル版ならではのアドバイスもあり、200msでレンダリングするヒントになる。
 スクロールせずに見える範囲のコンテンツのサイズを削減する — Google Developers CSS の配信を最適化する — Google Developers  これらの記事で述べられていることは、above-the-foldコンテンツを速く見せろということ。</description>
    </item>
    
    <item>
      <title>HTTPリクエストを減らすために【DataURI編】遅延ロードでレンダリングブロックを回避</title>
      <link>https://t32k.me/mol/log/reduce-http-requests-datauri/</link>
      <pubDate>Thu, 22 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/reduce-http-requests-datauri/</guid>
      <description>このシリーズはHTTPリクエストの理解を通じてWebパフォーマンスの重要性について考える5章構成になっている。
 【序章】HTTPリクエストは甘え 【CSS Sprite編】スプライト地獄からの解放 【WebFont編】ドラッグ＆ドロップしてコマンド叩いてウェーイ 【DataURI編】遅延ロードでレンダリングブロックを回避 【終章】我々には1000msの猶予しか残されていない  4日目は、本ブログでも何回か話題にしているインライン画像についてです。
 データURIスキーム CSS Sprite画像はDataURI画像にすべきか？  Data URI画像のテスト結果について 以前の記事で私は以下のように述べましたが、これはいやらしい表現だ。
 DataURIの画像は、通常の画像に比べて6倍遅いとかゆう記事もある
 このような『xxx倍高速化』、『xxx倍遅い』と言った表現は、わかりやすい反面、本質を見失ってしまう危険性がある。例えば、10秒が1秒になるのも、1秒が0.1秒になるのもどちらも同じく『10倍速くなった』と表現できる。
似たような例として、毎年のようにブラウザのJavaScriptエンジンがx倍高速化した！といったようなニュースを一度は聞いてるかと思うが、実体感としては、それほど速くなっていないように感じる。これも結局はブラウザのJS処理なんてものは何msという単位（あるいはもっと細かい単位かもしれません）での改善なので、そのような文脈での『x倍』というのは、実際は0.数ms程度の違いしかないということだろう。
このように『x倍速くなった・遅くなった』という表現をしているときは、注意が必要だ！（大人はみんな騙そうとしてくる）どうゆう文脈での何倍なのか、ちゃんと確認する必要がある。
 In the first condition, the src image attribute was specified to an image location known to be in the browser cache. This is called the binary condition.In the second condition, the src image attribute was specified to a pre- fetched data URI of the same image as in the first condition.</description>
    </item>
    
    <item>
      <title>HTTPリクエストを減らすために【WebFont編】ドラッグ＆ドロップしてコマンド叩いてウェーイ</title>
      <link>https://t32k.me/mol/log/reduce-http-requests-webfont/</link>
      <pubDate>Wed, 21 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/reduce-http-requests-webfont/</guid>
      <description>このシリーズはHTTPリクエストの理解を通じてWebパフォーマンスの重要性について考える5章構成になっている。
 【序章】HTTPリクエストは甘え 【CSS Sprite編】スプライト地獄からの解放 【WebFont編】ドラッグ＆ドロップしてコマンド叩いてウェーイ 【DataURI編】遅延ロードでレンダリングブロックを回避 【終章】我々には1000msの猶予しか残されていない  3日目は、スマホ環境であればHTTPリクエストを減らすためにWebフォントの採用を考慮しても、やぶさかではないだろう。
まずは下記の画像をご覧頂きたい。
これはプロジェクトで私が使用していたスプライト画像だが（実際は縦にして使用）、このような単純な形状、単色のアイコンであれば、Webフォント化したほうがなにかと都合がよい。
このスプライトであれば、カラー × 矢印の向き × シャドウの有無 パターンの可能性があり、スプライトすれば1リクエストでおさまるが、それでも画像が肥大化していけば、Receivingが無視できない状況になってくる。
そこでWebフォント化すれば色は自由に変更可能だし、フォントなのでtext-shadowで影を当てることも可能、font-sizeで大きさも変更でき柔軟に対応することができる。
それではWebフォントって一体どうやって作るのだろうか？高いフォント作成アプリを購入しなければならないのだろうか？オンライン作成ツールもあるようだが、毎回、新規アイコン追加の度にそのツールのサイトを訪問しなければならないのだろうか？
 ❍ IcoMoon - icon font &amp;amp; SVG icon sets  以前は上記オンラインツールを使っていたが、やはり更新対応を考えるとめんどうだった。そうゆうわけで、Mapleプロジェクトではgrunt-webfontを導入している。
前回の記事を見ながらMapleプロジェクトを準備してもらいたい。そのほかの必要環境として以下のものインストールしておく。Homebrewも入っていなければインストールする。
$ brew install fontforge ttfautohint $ brew install https://raw.github.com/sapegin/grunt-webfont/master/Formula/sfnt2woff.rb あと事前に必要になるのはフォントの元となるSVGファイル。SVGファイルを作るうえで便利なテンプレートがあるのでそれを拝借する。
 cognitom/symbols  テンプレートを使ってMapleでは上記のようなイラレファイルを作成した。iconmonstrにはいろいろ使い勝手がいいアイコンが無料で配布されているので、ここから必要なものをとってくるのもいいだろう。Illustratorでアートボード別に書きだして、SVGファイルとして保存する。要注意なのはこのアートボードの空白部分も含めてSVGファイルなので気をつける。
基本的にこの部分はデザイナーさんにやってもらえればよいことなので、フロントエンドデベロッパーは完成したSVGファイルを、/src/files/font/svgディレクトリに投げ込んでコマンド打つだけだ。
$ grunt webfont Running “webfont:dist” (webfont) task Font ‘myfont-b5fd89266afbbfbfc281a0ce9a5bf50e’ with 13 glyphs created. で、/src/tools/でgrunt webfontを実行すれば上記のようなログとともに、.woffと.ttfと_myfont.scssが作成される。
// _setting.scss //------------------------------------- @import &amp;#34;../vendors/myfont&amp;#34;; // _myfont.scss .</description>
    </item>
    
    <item>
      <title>HTTPリクエストを減らすために【CSS Sprite編】スプライト地獄からの解放</title>
      <link>https://t32k.me/mol/log/reduce-http-requests-css-sprite/</link>
      <pubDate>Tue, 20 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/reduce-http-requests-css-sprite/</guid>
      <description>このシリーズはHTTPリクエストの理解を通じてWebパフォーマンスの重要性について考える5章構成になっている。
 【序章】HTTPリクエストは甘え 【CSS Sprite編】スプライト地獄からの解放 【WebFont編】ドラッグ＆ドロップしてコマンド叩いてウェーイ 【DataURI編】遅延ロードでレンダリングブロックを回避 【終章】我々には1000msの猶予しか残されていない  2日目は、HTTPリクエストを減らす最もポピュラーな手法、CSSスプライトについて説明する。
まずは動画をご覧頂きたい。
  img要素読み込み | WebPagetest Test Result CSS Sprite読み込み | WebPagetest Test Result  左が30個のアイコン画像を一つ一つimg要素として読み込んでいるのに対して、右は１つの背景画像（CSSスプライト）として読み込んでいる。この場合、表示完了までの差はCSSスプライトのほうが圧倒的に速い。
これは前回のHTTPリクエストの仕組みを理解していれば当然のことだろう。つまり、ホスト名ごとの同時接続数とRTTが大いに関係している。上記のimg画像読み込みのウォーターフォールチャートを確認してみれば一目瞭然だ。CSSスプライトすることで一つの画像ファイルサイズは重くなるが、この場合、重要なのはReceivingの時間というよりWaitingの時間なので、結果的にアイコン表示までの時間を短縮できている。
CSSスプライトの仕組み自体は簡単もので、任意の要素の中で背景画像の位置を調整して表示している。実際に表示されるのは要素で指定したwidth/heightの分だけなので、あたかも1個の独立した画像のように見えるだけだ。
CSSスプライトは非常に便利だが問題点もある。スプライトのジレンマというのがあり、ページ数、保守性、最適化 の観点から評価し、スプライトをする上でこの3つの中から2つしかとれない。
例えば、多くのページ数を保守性を保ちながらスプライトすると、最適化はちょっとあきらめなければいけない。また、多くのページ数を可能な限り最適化すれば保守性はあきらめなければならない。また、保守性を意識しつつ最適化すれば、適用できるページ数は少なくなってしまうようにだ。
画像の変更があるたびにPhotoshopを開いて、画像を置き直して、その位置をルーラーで割り出す。それがRetina画像であれば、実際のbackground-positionサイズから半分にしないといけない。気の遠くなるような面倒くさいタスクだ。面倒くさくなくてもヒューマンエラーというのは起こるもので、単純な割り算（この場合Retina対策として背景位置を半分にする）でも、何回も繰り返せば、ミスは必ずでてくる。そしてそのミスに気づかず数時間ロスをすることもままだ。
もう、なんというかCSSスプライトが嫌すぎてデザイナーと喧嘩することもしばしば。これでは精神衛生上よくない。
そこでそのめんどくさいタスクSass/CompassのMixinにやってもらおうと思う。
 CSS Sprite for Retina Display Maple.css  まず、Mixinの説明する前に私が作っているMapleプロジェクトをダウンロードしてくる（Node.js, Ruby, Sass, Compassがインストールされていること前提）次に、grunt-init-mapleをインストールする。
$ npm install -g grunt-cli $ npm install -g grunt-init $ git clone https://github.com/t32k/grunt-init-maple.git ~/.grunt-init/maple –recursive grunt-init mapleを実行すると以下のようにMapleプロジェクトに必要なファイルがスキャフォルディングされる。
落ちてきたら、/src/tools（Gruntfile, package.jsonがある場所）に移動し、必要なGruntプラグインをインストール（npm install）しておく。これで下準備はOK。
その場所でgrunt developしてhttp://localhost:8080/components/を見にいく。そこにスプライトした画像が表示されていますからDevToolsなどで確認してみる。
.sprt-a { background-image: url(/files/img/sprite/tabs-s3217a038c5.</description>
    </item>
    
    <item>
      <title>HTTPリクエストを減らすために【序章】HTTPリクエストは甘え</title>
      <link>https://t32k.me/mol/log/reduce-http-requests-overview/</link>
      <pubDate>Mon, 19 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/reduce-http-requests-overview/</guid>
      <description>このシリーズはHTTPリクエストの理解を通じてWebパフォーマンスの重要性について考える5章構成になっている。
 【序章】HTTPリクエストは甘え 【CSS Sprite編】スプライト地獄からの解放 【WebFont編】ドラッグ＆ドロップしてコマンド叩いてウェーイ 【DataURI編】遅延ロードでレンダリングブロックを回避 【終章】我々には1000msの猶予しか残されていない  1日目は、HTTPリクエストの概要について説明する。
例えに、私のポートフォリオページ（t32k.me）が表示されるまでの流れを見ていく。まず、検索からでも方法はなんでもよいが、ブラウザのURLバーにt32k.meと打ち込んでアクセスする。そのページを見にいくということは、つまりt32k.meに対してHTTPスキームでリクエストするということを意味している。
クライアントであるブラウザは入力されたURLを判断して、リソース（この場合、HTMLファイル）を要求しにいきます。このとき、t32k.meというドメインはあくまで人間が覚えやすいように考えられた名前なので、ブラウザはこれだけではリソースに到達出来ない。
そこで、この名前であるドメインをIPアドレス（eg. 192.0.2.0）に正引き（変換）する必要性がある。この作業をDNS Lookup（名前解決）という。たいていISPのDNSサーバーに問い合わせたりして解決する。
 DNS - Domain Name System  IPアドレスが分かったので今度はサーバーに接続しにいく。クライアントは『サーバーさんいる？』と聞き、サーバーは『いるで！』と答える。このやりとりをConnectingといい、ソケット接続が確立することを意味する。
なぜ最初からリクエストを通さないのかというと、それだと受け手の状況がわからないので通信の信頼性が担保されないからだ。詳しくはTCPのスリーウェイハンドシェイクという仕組みを参照。
 TCP - Transmission Control Protocol  サーバーとの接続が確立したので、ここでやっとHTTPリクエスト、つまり、index.htmlを要求する。このとき、動的ファイルだったらファイル生成などプロセスが走る。そのあと見つけた・生成したファイルをクライアントに送信する。送信した最初のパケットがクライアントに届いた時点までが、Waitingの時間になる。
そして最後のパケットが送り終えた時点までが、Receivingの時間になる。ここがいわゆるファイルのダウンロード時間にかかる時間。
ちなみに、これらのタイミングにかかる時間はGoogle ChromeのDeveloper ToolsのNetworkパネルのTimingタブで確認できる。
このHTTPリクエストの中身を確認して言えることは、クライアントとサーバーとのやりとりにかかる時間、ラウンドトリップタイム(RTT)と、リソースのダウンロードにかかる時間（DL）が重要だということ。
 RTT - Round Trip Time  t32k.meのネットワークにかかる情報をまとめたHARファイルに保存して（DevToolsのネットワークパネルで右クリック保存）、HAR Viewrで見たものが以下。分かりやすくするために、3G回線でエミュレートした結果を表示している。
 HAR - HTTP Archive format  どうだろうか、見た感じで紫色のバーが多いことに気づくことだろう。つまりWatitingに多くの時間がかかっていることが理解できる。これは単純にサーバーの処理が遅くて時間がかかっているのではなく（かかっているあるが）、たいていはホスト名ごとの同時接続数に起因するものだ。
ひとつの完全修飾ドメイン名 (FQDN: Fully Qualified Domain Name)に対して、同時接続できる数はたいてい6つまでだ。これを超える数のリクエストがくると、7つ目のリクエストは、最初の6つのリクエスト処理がどれかが完了される間、待たなければならない。この時間も待ち時間になる。
このような制限のため、静的ファイルはstatic.t32k.meなどの別ドメインから読み込むことによって、この同時接続数の上限を最大化しようとするのがドメイン・シャーディング（Domain Sharding）という手法が一般的にとられる。
このおかげで並列ダウンロードできる数を増やし、リソースのWaitingを可能な限り少なくしている。並列ダウンロード数が増えるからといって、例えば10個の違うドメインから読み込んだとすれば、クライアントの最大コネクション数を大きく超えて意味がなかったり、また最初に説明したDNSルックアップの時間が増えたりして、逆に弊害をもたらすようになるので、2,3つあたりのドメインを使うのが無難だろう。
すべてのHTTPリクエストで以上のようなことが行われているかというと、そうでもないだろうが、HTTPリクエストをするということは非常にコストの高い行為だということが分かって頂けたかと思う。
ネイティブアプリは初回のアプリダウンロードで、アプリ内にリソースがまとめているので、このようなことは気にしなくてもほぼ良いだろう。しかしWebアプリとなると、いかにサーバーとクライアントのやりとりを減らすか、がボトルネックとなる。特にRTTに関しては、根本的に改善するにはサーバーをユーザーの近くに置く(Akamai等)ことしかできないので、フロントエンドの人間にとってはラウンドトリップさせないということが重要になってくる。
次回からはCSSスプライト、Webフォント、DataURIなど実践的なテクニックを使ってHTTPリクエストの減らし方について学んでいきます。
ハイパフォーマンスWebサイトposted at 2015.1.18Steve Souders</description>
    </item>
    
    <item>
      <title>CSS Sprite画像はDataURI画像にすべきか？</title>
      <link>https://t32k.me/mol/log/sprite-image-vs-inline-image/</link>
      <pubDate>Wed, 31 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/sprite-image-vs-inline-image/</guid>
      <description>最近、スプライト画像はDataURIにすべきですか？という質問が多くて、調べてみました。てか、前のもそんな話題があったような。DataURIってなんぞって方は下記を見てほしい。
 データURIスキーム | MOL   CSSファイルがパースされなければレンダリングが始まらないのでCSSファイルの肥大化は絶対に避けなければならない。画像の1KBとCSSファイルの1KBを同じように考えてはいけない。 ― ぼくのかんがえたさいきょうのしーえしゅえしゅ 
 あ、ホントそうだっけーなーと思いつつ、どこぞの資料見たんだっけなーと探してたらあった。
 Optimizing the Critical Rendering Path for Instant Mobile Websites - Velocity SC 2013
このセッションはすごく分かりやすいのでオススメです（該当の箇所は12分位から）。というかIlya Grigorik ++
セッション中の資料には、ご覧のとおり、HTMLがパースされてDOMが完成したところで、画面には何も表示されない。感覚的には、スタイルのついてない『Hello world!』くらい表示されてもいいじゃんか！と思うんだけど、表示されない。
次に、CSSがパースされてCSSOM（CSSのDOMみたいなもの？Style Rulesとかとも言ったりする）が構築されるが、まだ画面は空白のままだ。
DOMとCSSOMがガッチャンコしてRender Treeが構築され、そこにレイアウト情報が加わって初めて描画となるんだね。この辺りの更に詳しい情報はHTML5 Rocksの以下の記事がすばらしいので読んでほしい（すぐ眠たくなるけど）。
 ブラウザのしくみ: 最新ウェブブラウザの内部構造 - HTML5 Rocks  ここで重要なのはHTMLと（読み込んでいる）スタイルシート（CSS）が無い限り、描画はされないということだ。つまり、CSSの読み込みに手間取ればCSSレンダリングをブロックするということが考えられる。
レンダリングをブロックするのはJSファイルだけかと思ってたけど、スタイルシート（CSS）も気をつけなければならないということが分かる。
そこで冒頭にも述べたように、CSSファイルを出来る限り軽くし、読み込みを速くすることでレンダリングのブロックを回避するという考えになってくると思うが、実際どんなもんなのよ？と思ったので、テストファイル作ってみた。
 Normal CSS Sprites Inline image CSS Sprites  30個くらいのアイコン画像をスプライト化して読み込んでいるのと、それをさらにDataURIにしているもの比較だ。それらをWebPagetestにかけてみた。
ビジュアル比較テスト結果  WebPagetest - Visual Comparison  各テスト結果  WebPagetest Test Details - Dulles : Normal&amp;hellip;/normal_sprite.</description>
    </item>
    
    <item>
      <title>パフォーマンスからみるSass/Compass 第1回：Nestingと@import</title>
      <link>https://t32k.me/mol/log/sass-nesting-and-import/</link>
      <pubDate>Thu, 12 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/sass-nesting-and-import/</guid>
      <description>Sassとかいろんな機能ありますよね、でもぶっちゃけそんなにいっぱい機能あっても使わないし( ･´ω･｀)　案外、//ダブスラでコメントアウトできるのが一番嬉しかったりもします今日このごろです。
@import というわけで、そんな僕がSassを使うと思ったのも@importを使いたかったからという至極単純な動機によるものです。@import自体は普通のCSSでも使えますが、パフォーマンス的に難がありまして、あんまり使う気になれない、かといってファイル管理はページ単位やコンポーネント単位でちゃんとやらないと後々めんどいなというジレンマもあります。
そうゆうわけで、なんで普通の@importがダメなのか説明します。 IEにおいて@importはページ下部に置いた&amp;lt;link&amp;gt;タグのような挙動をします。
Best Practices for Speeding Up Your Web Site  Yahoo!のパフォーマンスベスト・プラクティスにおいて、上記のような記述がありました。Styleの情報というのはできる限りページ上部に置いてレンダリングを早く開始させる必要があるのでこれは頂けませぬ。
まぁ基本的に@importのパフォーマンス的問題はIE以外ならOKであれば使ってもいいのかなと思ってたんですけど、よくよく調べてみるとそうでもなかったですという話。
/* first.css */ @import url(&amp;quot;second.css&amp;quot;)  まぁ上記のような&amp;lt;link&amp;gt;で読み込んだfirst.cssでsecond.cssを@importするといった例があるとします。これがどのような挙動をするのかと言いますと、
ブラウザーはsecond.cssをダウンロード可能と発見する前に、必ずfirst.cssのダウンロード、パース、実行をする。 Minimize round-trip times - Make the Web Faster — Google Developers Googleの方には上記のようなことが書かれていました。つまり、first.cssを読み込み完了してからsecond.cssを読み込みに行くので並列ダウンロードができないってことです。これってIEに限ったことではなくてすべてのブラウザーで起こりうることらしいです。マジかいや！てことで、Steve Soudersセンセのテストケースを最新のChromeのNetworkパネルで見てみると本当にそうでした。さーせん！ということで、やっぱり普通の@importは使うべきではないですな。
詳しくは下記ブログ読むと良いよ。  don’t use @import | High Performance Web Sites   まぁ、そうゆうわけでSassの@importですよ。基本ローカル環境でコンパイルして一つのCSSファイルにまとめるので、読み込むのは実質1ファイルだけになるんですね。それでいて、ページ単位やコンポーネント単位でファイル分割できるのでコードの見通しも悪くならない、素敵です。sass &amp;ndash;watchとかScoutとか使えば毎回手動でコンパイルしなくても更新があれば自動的にコンパイルしてくれます。 // Sass @import &amp;ldquo;_reset&amp;rdquo;; @import &amp;ldquo;_common&amp;rdquo;; @import &amp;ldquo;_header&amp;rdquo;; @import &amp;ldquo;_main&amp;rdquo;; @import &amp;ldquo;_footer&amp;rdquo;; これだけのためにでもSass導入してもいいんじゃないかと個人的には思っています。
Nesting あと、便利っちゃー便利なのがネストです。下記のようにセレクタ、プロパティの重複する部分ってのを省略して書けます。
// Sass table.</description>
    </item>
    
    <item>
      <title>Long Life Web Performance Optimization</title>
      <link>https://t32k.me/mol/log/long-life-web-performance-optimization/</link>
      <pubDate>Wed, 24 Nov 2010 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/long-life-web-performance-optimization/</guid>
      <description>WCAF Seminar Vol.4での講演ログ。
 タイトルのLong Life Web Performance Optimization、長いのでLong Life WPOって略します。これは、Long Life Designからもじりました。Long Life Design というのはD&amp;amp;DEPARTMENT PROJECTのナガオカケンメイさんが行っているプロジェクトで、60年代とか70年代の昔の優れたデザインを今にも伝えて使い続けていこうって趣旨だったと思います。
それに対して、Webの世界はどうでしょう？移り変わりが早いですよね。「お！これが90年代のテーブルレイアウトかぁ〜エクセレント！」なんてことはない。そこで今回はLong Life Designのように長〜く使えるWPOを心理学などの人間側から考えてみようってのが今回のセッションの狙いです。
最近のパフォーマンス事情 最近パフォーマンスの話、聞かないですよね？去年の暮れあたりが賑わい的にピークだったかと思います。(※Googleのランキングアルゴリズ追加に関しても情報全くないですし…)とはいえ、結構パフォーマンス事情は賑やかですってのをこれから紹介していきます。
Web Performance Working Group もっともビッグなニュースと言えば、W3Cで8/19にWeb Performance Working Groupが設立されたことです。このWorking GroupのミッションはWebアプリケーションのパフォーマンス計測のための仕様を作ることです。共同議長にはMicrosoftとGoogleの方がいます。この辺からMSのWebパフォーマンスに対する本気度が伺えますよね。今後に期待です。
API for Measuring Web Performance そこで策定されていくのが計測のためのAPIです。で、そのAPIとはなんぞや？ってことなんですけども、
  Navigation Timing ネットワークや読み込みなどの時間、リクエスト回数などの情報を取得することができます。 Resource Timing 画像やスクリプトなどのリソースを読み込むときの時間、情報を取得することができます。 User Timing UAがコードを実行した時間を取得することができます。    2010年8月のW3C | Web標準Blog | ミツエーリンクス  window.performance.navigation.loadEnd みたいな感じでページの読み込み時間が簡単に分かるようになるんですね。つまり、YSlow や PageSpeed などのプラグインなしでも詳細な情報が取得することができます。このAPIを実装しているブラウザは共同議長の選出先と同じようにIE9とChrome6からとなっています。
Boomerang.js それじゃ利用するにはまだまだ先の話だと思うのですが、そうでもないんですね。次に紹介するのはオープンソースのパフォーマンス計測ライブラリのBoomerang.js です。開発者は Yahoo! Inc. の Philip Tellis さんです。この Boomerang.</description>
    </item>
    
    <item>
      <title>Coding Web Performance</title>
      <link>https://t32k.me/mol/log/coding-web-performance/</link>
      <pubDate>Mon, 06 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/coding-web-performance/</guid>
      <description>CSS Nite LP, Disk 9での講演ログ。
 ビジネスインパクトとスタンス Webパフォーマンスがビジネスにおける大きなインパクトといえば、Googleのランキングアルゴリズムにページの読み込み速度が組み込まれたことではないでしょうか。2010年4月9日の時点ではgoogle.comで英語で検索された場合にしか適用されません。また、パフォーマンスが考慮された検索クエリも1％未満とまだまだな状況ですが、いずれ日本でも適用される日がくるかと思われますので、今日はそのWebパフォーマンスについて、お勉強をしましょう。
しかし、このGoogleの評価は何をもって速いとするのでしょうか？公式ブログでは様々な指標をもとに比較検討しています…とのことでした。一体何を言っているのでしょうか… とりあえず、分かっている計測基準として2つあるので紹介したいと思います。
Google AdWords まずはAdWords、Googleの広告サービスですね。実はAdWordsの方では2008年4月の段階から品質スコアの評価にページの読み込み速度が取り込まれていました。品質スコアが高ければ、広告の掲載順位は高くなり、料金も安く抑えられます。この計測方法なんですけども、AdWordのヘルプの方にはHTMLのダウンロード時間と記載されています。現在はまだHTMLファイルだけなんですけども、後々画像やJSファイルといった外部ファイルの計測も行われるようです。スライドの黄色部分に「リンク先ページの読み込み時間に、問題ありません」と書かれています。つまり、もしあなたの会社がAdWordsに出稿しているのであれば、Webパフォーマンスは既に対処しなければならない案件になっているということです。
Google Webmaster Tools 次にウェブマスターツールなんですけども、2009年の12月に「サイトのパフォーマンス」という項目が追加されました。これは文字通りサイトの読み込み速度に関する情報が表示されます。では、何をもって速い・遅いとするのかですが、このツールではGoogleが収集したデータの上位20％が早く、残りの80%が遅いと決めているようです。そのラインが平均読み込み速度が1.4秒、スライドの赤いラインです。そうゆうわけで、私たちの目下の目標としてはこの1.4秒以下に読み込み速度を抑えるということになります。こちらの計測方法ですが、Googleツールバーをインストールしたブラウザでなおかつページランク機能を有効にしたユーザーの読み込み込み時間となっています。AdWordsの方はHTMLファイルだけの読み込み時間ですが、こちらは実際の状態に近い計測手法となっています。
そんなわけで、ほかにもいろんな計測をしていると思うのですが、とりあえずはこの2つを意識して対策をしていけば良いでしょう。
高速サイトがもたらす利益 高速サイトがもたらす利益としては、検索だけではありません。ベージが速く読み込まれればそれだけユーザのストレスがなくなるわけですから、再訪問数の増加やセッションあったりのPV数増加にもつながります。そうすればおのずとコンバージョン率の改善、そして収益増加。また、売上が上がるということは顧客満足の向上した結果とも言えます。そういった売上の増加だけでなく、ページをコンパクトにまとめることでサーバーの転送量が少なくすることができれば、インフラコストや帯域幅の節約などにもつながります。
さて、こういったビジネスインパクトがコーダーに与える影響の面を考えると、コーダーはパフォーマンスという武器を手に入れることになるのではないでしょうか。というのも、デザイナーもそうですが、ただ単純にキレイなデザイン・キレイなコードというのはクライアントさんや、その上のマネジメント層にとっては興味のないことであって、彼らが知りたいのは売上です（そもそも彼らの仕事は数字を見ることですからね）。
ですから、商品をできるだけ目立たそうとして、デザイン的に無理な要求であったり、例外処理ばかりのコードになることも多々あります。そこで、私はデザイナーとして「トーンアンドマナーが…」など言うのですが全然聞いてくれません。ところが隣のSEOチームが「いや、それはSEO的に良くないのでやめて下さい」と言えば、素直に従ってくれます。
これはまぁ、SEO的に悪い＝検索順位が下がる＝売上が下がるといった思考パターンですよね。つまり、今回WebパフォーマンスがGoogleのランキングアルゴリズムに組み込まれたということで、その程度はどうであれ、SEOとパフォーマンスを絡めることができる。そしてパフォーマンス対策できるコーダーの存在感が高まるのではないでしょうか。社内の存在感が高まれば、それだけ自分の好きなこと・やりたいことを貫ける可能性も高まるのではないかと私は考えます。
とはいえ、コーダー・デザイナーは忙しいです。HTML5/CSS3は次から次へといろんなAPI、プロパティが出てきています。最近、jQueryナウいよねってことでJavaScriptを多用すれば、アクセシビリティやユーザービリティに関しても気を使わなければなりません。またサイト全体の情報アーキテクチャも考えなければならないし、アクセス解析も嗜みたいところ。そこで、今回取り上げるWebパフォーマンスですか？それはちょっと、無理無理カタツムリよーってことで。
とはいえ、来週あなたの上司が「パフォーマンス対策はどうなっとらんやー！」って聞いてきたらどうしましょうか？HTMLのコード量を減らしましょうか？JSの変数名やCSSセレクタを短いものに置き換えていきましょうか？そういった明後日の方向に進まない（まず最初に取り組まなければならない問題ではない）ためにも今回のセッションの目的は最小限の対策で最大限の効果をあげれるような対策を紹介します。
ボトルネックはどこか？ 最小限の対策で最大限の効果をあげるためには、ボトルネックを探しそれを取り除いてあげればいいんですね。とは言っても、Webパフォーマンスという目に見えないものを対策するにあたって、それをビジュアライズするツールが必要になってきます、それが、このHTTPWatchです。こういったツールは他にもFirebugの接続パネルやSafariのリソースパネルなどがありますが、HTTPWatchはWindows上でIEとFxで動作するので採用しています。
 HttpWatch: HTTP Sniffer for IE, Firefox, iPhone and iPad  このツール最大の機能はウォーターフォールチャートです。これが何を表しているのかというと、ページの読み込まれ方を表しています。この1つ1つのバーがページのコンポーネント、画像であったり、CSS、JSファイルであったりページの部品を表しています。横軸が時間経過を表しているのでこれが横に長ければ長いほど読み込み時間に時間がかかかっているのが読み取れます。とは言っても、バーの赤色とか緑色は何を表しているの？って感じですよね。HTTPWatchのヘルプには以下のように記載されていました。
 ブロッキング DNSルックアップ コネクト - 接続 センド - 送信 ウェイト - 待機 レシーブ - 受信 キャッシュ読み込み  用語だけ言われても分かりませんので、具体的に見ていきますと。まず、サーバーとクライアントであるブラウザがあります。例えばCSS Niteの公式サイトを見たいとするのならば、ブラウザのURL欄にcssnite.jpと打ち込むでしょう。
そうすると、ブラウザは打ち込まれたURLをIPアドレスに変換するためにISPなどに問い合わせにいきます。そして問い合わせた結果が届いた時間までがDNSルックアップです。
次に、そのIPアドレス上にあるサーバーに接続を試み、うまく接続できたならばOKのレスポンスを返します。ここまでがコネクトです。ソケット接続とかTCP接続などと呼ぼれる部分です。この部分は持続接続可能なので2回目以降は省略されます。
そして次がもっとも大事なHTTPリクエスト。cssnite.jpのindex.htmlなどのリソースを探しにいきます。そしてサーバーがこれねこれね、ということで見つけたリソースの最初のパケットデータが届いた時点がウェイトです。
そして残りのデータをすべて送りブラウザに届いた時点がレシーブです。このレシーブが一般的にファイルのダウンロード時間と考えらています。
このことをふまえて、もう一度先ほどのウォーターフォールチャートを見て見ますと、どうでしょうか？何色が目立ちますか？どう見たって赤色ですよね。
Webパフォーマンスと言われるとファイルのダウンロード時間を短くすればいいんじゃね？と考えがちなんですが、この場合、緑色の部分はなんてほとんどないですよね。
そもそもこのウォーターフォールチャートはどこのページを読み込んでいるかというと、後ほど紹介するとある一般的な企業サイトです。どのコンポーネントも数キロバイトの画像です。
このスライドから読み取れるに、4キロバイトの画像も5キロバイトの画像もダウンロードにかかっている時間はそう変わらなくて（だからと言って画像の最適化を怠ってはいいということではありません）、ダウンロード時間の何倍もの時間をウェイト時間に費やされているのが分かります。ウェイト時間はサーバーの待ち時間なので、私たちデザイナー・コーダーにとってはどうしようもできない部分です。必ずかかる税金のようなものです。
この状況をハンバーガー屋さんで例えてみますと、レシーブ時間をハンバーガーを作る時間、ウェイト時間をお会計にかかる時間とします。さらにこのお店は一回の注文につき一つの商品（リクエスト）しかできません。つまりチーズバーガーが2個欲しければ、チーズバーガー１つくださいと言って、作ってもらってお会計をして、またチーズバーガー１つのくださいと言って作ってもらってお会計するというようなめんどくさいことをしなければなりません。
もう一度、先ほどのウォーターフォールチャートを見てみますと、これは実はIE6で読み込まれたウォーターフォールチャートです。ここにはもう一つ重要なことが隠されていてます。
とりあえず、この同じページをFirefox3.6で読み込んでみますとこのようなウォーターフォールチャートになりました。皆さん、一体どこが違うでしょうか？ここでは、バー1つ1つの長さは比較対象にはしていません。それよりも、なんだかコンポーネントの読み込まれ方が違いませんか？どうやらIEのほうはなだらかに読み込まれていて、Fxの方は急な勾配になっているのが分かりますね。これがどういった違いによるものかと言いますと、</description>
    </item>
    
    <item>
      <title>High Performance Web Design</title>
      <link>https://t32k.me/mol/log/high-performance-web-design/</link>
      <pubDate>Tue, 24 Nov 2009 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/high-performance-web-design/</guid>
      <description>CSS Nite in ISHIKAWA, Vol.1での講演ログ。
 What’s High Performance? ハイパフォーマンスWebサイトposted at 2015.1.17Steve Souders,スティーブ サウダーズ
オライリージャパン
売り上げランキング: 101136
Amazon.co.jp で詳細を見る ここでいうパフォーマンスというのはWebサイトの表示高速化についてです。つまり、ページをいかに早く表示させるかという課題です。でも、そうゆうのってサーバー側の問題でしょ？システムエンジニアの管轄じゃないの？と思われがちですが「ハイパフォーマンスWebサイト」の著者であるSteve Soudersの調査によると、80:20。一般的にユーザーの待ち時間の実に80%がブラウザ側、フロントエンドで費やされていて、サーバー側、バックエンドでの時間は全体の20%でしかないという結果が出ています。つまり、サーバー側でデータベースのチューニングやメモリ管理、アルゴリズムの見直しなどして処理時間を半分にできたとしても全体として見れば10%でしかないということです。要するにフロントエンドを預かるWebデザイナーの責任が重大と言うことです。
Why High Performance? では、なぜパフォーマンスが重要なのでしょうか？パフォーマンスが悪いと何か都合が悪いのでしょうか？パフォーマンスをないがしろにしていると怖いよっていうデータを見せたいと思います。
Google 0.5秒遅くなると、検索数が20%減少する うん、怖いですね、メインの事業ですからね。
 We&amp;rsquo;re all guinea pigs in Google&amp;rsquo;s search experiment - CNET  Amazon 0.1秒遅くなると、売り上げが1%減少する 怖いですね、たった0.1秒遅くなることで数十億、数百億ぐらいの影響になってくるということです。このようにパフォーマンスが低下すれば収益に直に影響してくるといったケースが考えられます。だけども、うちはAmazonみたいに大きくないから考えすぎだよとおっしゃりたいかもしれません。
 Make Data Useful by Greg Linden, Amazon.com  Aberdeen Group Aberdeen Groupというリサーチ会社が出したレポートによると、一般的に表示スピードが1秒遅くなると、PVは11%、CVは7%、顧客満足度は16%ダウンするといったことが報告されています。こういった数値を知っていればパフォーマンス対策をするための目標を決めやすいのではないでしょうか。またユーザービリティ的に見てもパフォーマンス低下は避けた方良いということが分かります。
反応時間の3つの重要限界  心理的・感情的な違和感を感じないのは0.1秒まで 思考の流れが妨げられないのは1秒まで 注意力を維持できる限界の時間は10秒まで  結局のところ、Time is Money！と言えるのではないでしょうか。つまり、ページをハイパフォーマンス化することでユーザーのストレスをなくし、ユーザーエクスペリエンス（体験）の質を向上させることで、結果収益にもつながってくるこということです。
 Response Time Limits: Article by Jakob Nielsen  How do I measure it?</description>
    </item>
    
    <item>
      <title>Design Fast Websites</title>
      <link>https://t32k.me/mol/log/design-fast-websites/</link>
      <pubDate>Wed, 24 Dec 2008 00:00:00 +0000</pubDate>
      
      <guid>https://t32k.me/mol/log/design-fast-websites/</guid>
      <description>『Chromeはなぜ速いのか』の記事が話題になっていて、少し内容がリンクしていたので紹介する。YSlowでおなじみのYahoo! Performance Teamのスライドだ。
 パフォーマンスに関するデザインの話なので、興味があった。まず、なぜパフォーマンスを意識しなければならないのか？ということに関して3つの理由を挙げている。
 Because fast is better Because sites are bigger Time is money  1つ目は、速いは正義。Webを速く表示することで誰も困らない。 2つ目は、年々Webサイトは大容量化してるそうだ。Ajaxを使ったWebアプリケーション、ディスプレイの大型化に伴うサイトのワイド化など考えられる。 3つ目、時は金なりということで、以下のようになっている。
 +100ms Amazon : 1% drop in sales +400ms Yahoo! : 5-9% drop in full-page traffic +500ms Google : 20% fewer searches  Amazonで0.1秒遅くなれば、1%売り上げが落ち、Yahoo!で0.4秒遅くなれば、全ページで5~9％のトラフィックが減少し、 Googleで0.5秒遅くなれば、検索数が20%落ちるそうだ。
Web開発の理念としては：
 デザインに敬意を払いなさい デザイナーは私たちのコードを内側から見たときと同じくらいに美しく巧みなビジュアルにしてくれる 元のデザインビジョンを尊重しなさい（一貫したデザインはクリーンなコードを生み、それがサイトを早くする）  などのようなことを挙げられている。
9つの実践としては、 あんまりというかほとんど聞き取れなかったので話半分に。
1. スマートなオブジェクトのコンポーネントライブラリを作りなさい これはそのままだね。レゴを作るかのようにモジュールを決めて冗長性を避けるってこと。
2. セマンティックなスタイルを一貫して使用しなさい 意味に即したスタイルを指定しなさいということかな。見出しなのに、10pxなんてありえないだろみたいな。
3. 透明になるように（内部で）モジュールをデザインしなさい 透過画像を使ってうまくデザイン要素を組み合わせることかな。
4. 画像の最適化とCSSスプライト この辺はsmush it!なんか使って画像を最適化しろみたいな内容。
5. 非標準のブラウザのフォントを避けなさい これはブラウザに搭載していないフォントを使いたいがために画像で書き出すことをやめろというのか、それともほんとに、font-familiyでマニアックな書体を指定するなってことかな。よく聞き取れなかった。</description>
    </item>
    
  </channel>
</rss>